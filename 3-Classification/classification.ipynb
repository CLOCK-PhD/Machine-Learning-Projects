{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python >= 3.5 nécessaire\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn >= 0.20 nécessaire\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Autres imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# pour rendre les sorties du notebook stable au cours des différents runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Pour faire de jolies figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# où sauvegarder les figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MNIST\n",
    "\n",
    "Pour ce chapitre, nous allons utiliser le jeu de données MNIST qui est un set de 70000 petites images de chiffres écrits à la main. Chaque image est labellisée avec son chiffre.\n",
    "\n",
    "*Scikit-Learn* fournit de nombreuses fonctions d'aides pour télécharger des JdD populaires, dont MNIST. Le code suivant va chercher le JdD :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les JdD chargés par *Scikit-Learn* ont généralement une structure dictionnaire similaire, comprenant :\n",
    "- une clé `DESCR`, qui décrit le JdD\n",
    "- Une clé `data` contenant un tableau avec une ligne par instance et une colonne par caractéristique (*feature*)\n",
    "- Une clé `target` contenant un tableau avec les labels\n",
    "\n",
    "Regardons ces tableaux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 70000 images, et chaque image a 784 caractéristiques, car chaque image fait $28*28$ pixels, et chaque caractéristique représente l'intensité d'un pixel (0 : blanc, 255 : noir).\n",
    "\n",
    "Regardons un chiffre du JdD. Tout ce dont on a besoin est de prendre un vecteur d'une caractéristique d'une instance, le mettre en tableau $28*28$ et l'afficher en utilisant la fonction `imshow()` de Matplotlib :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure some_digit_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dans le livre : some_digit = [0]\n",
    "# Cette syntaxe ne fonctionne pas pour extraire en tant que tableau la ligne 0 d'un DataFrame pandas\n",
    "# J'ai donc utilisé la méthode un peu bourrin juste en dessous\n",
    "some_digit = X.iloc[0].to_numpy()\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "save_fig(\"some_digit_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le label est un `string`, donc il faut le *cast* en `integer` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.astype(np.uint8)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le JdD MNIST est déjà découpé avec son JdE (les 60000 premières images) et son JdT (les dernières 10000 images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le JdE a déjà été mélangé, ce qui est une bonne chose puisque cela nous garanti que les blocs (*folds*) de validation croisée seront similaires (on ne voudrait pas qu'un bloc ne dispose pas d'un type de chiffre). De plus, certains algo d'apprentissage son sensibles à l'ordre d'entraînement des instacnes, et ont de mauvaises performances s'ils ont plusieurs instances similaires dans une ligne. Mélanger (*shuffle*) le JdD assure que cela n'arrive pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un classificateur binaire (*binary classification*)\n",
    "\n",
    "On va simplifier le problème pour l'instant, et essayer de n'identifier qu'un seul chiffre : le 5.\n",
    "Ce détecteur de 5 sera un classificateur binaire, capable de distinguer deux classes uniquement : \"5\" et \"pas 5\".\n",
    "\n",
    "On crée le vecteur cible pour cette tâche de classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) # True pour tous les 5, False pour tous les autres chiffres\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on va choisir un classificateur et l'entraîner.\n",
    "\n",
    "Un bon point de départ est le classificateur *Stochastic Gradient Descent* (`SGD` - Gradient de descente stochastique), qu'on peut utiliser avec la classe *Scikit-Learn* `SGDClassifier`. Il a l'avantage d'être **capable de gérer de très grand JdD efficacement**. C'est en parti dû au fait que SGD **gère les instances d'entraînement indépendemment, une à la fois** (ce qui le rend également **adapté au _online learning_**).\n",
    "\n",
    "On va créer un classificateur `SGDClassifier` et l'entraîner avec tout je JdE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "# Si on veut des résultats reproductibles, il faut définir le paramètre random_state\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant l'utiliser pour détecter les images du chiffre 5 :µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remycosta/.local/lib/python3.8/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un message d'erreur inattendu suite à la conversion des données, c'est gênant, mais au final on le bon résultat puisqu'il a détecté que notre image représente un 5.\n",
    "\n",
    "## Mesures de performances\n",
    "\n",
    "Évaluer un classificateur est souvent beaucoup plus complexe qu'évaluer un régresseur (*regressor*), donc on va passer un certain temps là dessus.\n",
    "Il y a beaucoup de mesures de performances disponibles, donc attention aux nouveaux concepts et acronymes.\n",
    "\n",
    "### Mesurer la précision avec la validation croisée\n",
    "\n",
    "Comme dans le chapitre 2, la validation croisée est une bonne manière d'évaluer un modèle\n",
    "\n",
    "#### Implémenter la validation croisée\n",
    "\n",
    "Parfois, on va avoir besoin de plus de contrôle sur le processus de validation croisée que ce que *Scikit-Learn* fournit à la volée. Le code suivant fait globalement la même chose que la fonction `cross_val_score()`, et print le même résultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([    1,     3,     4,     5,     7,     8,    10,    11,    12,\\n               13,\\n            ...\\n            59984, 59985, 59987, 59988, 59989, 59991, 59993, 59994, 59996,\\n            59998],\\n           dtype='int64', length=40000)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-006984c99230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclone_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_train_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my_train_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_test_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([    1,     3,     4,     5,     7,     8,    10,    11,    12,\\n               13,\\n            ...\\n            59984, 59985, 59987, 59988, 59989, 59991, 59993, 59994, 59996,\\n            59998],\\n           dtype='int64', length=40000)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc encore un truc qui ne marche pas ici, et ça a l'air plutôt compliqué de régler le problème, donc on va essayer la suite.\n",
    "\n",
    "On va maintenant utiliser la fonction `cross_val_score()` pour évaluer notre modèle `SGDClassifier`, en utilisant une validation croisée à K-blocs, avec 3 blocs. On rappelle que la validation croisée en K-blocs divise le JdE en K blocs et fait ensuite des prédictions et les évalue sur chaque bloc en utilisant un modèle entraîné sur les autres blocs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient des résultats très intéressants, avec plus de 95% de précision. Avant de s'emballer, on va regarder un autre type de classificateur débile qui se contente juste de classifier chaque image dans la classe \"pas 5\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons la précision de ce modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% de précision : c'est simplement parce qu'environ 10% des images sont des 5, donc si on devine à chaque fois qu'une image n'est pas 5, on aura raison 90% du temps.\n",
    "\n",
    "Cet exemple était pour montrer que la précision n'est généralement pas la mesure de performance préférée pour les classificateurs, particulièrement quand on travaille avec des JdD biaisés qui ont des classes beaucoup plus fréquentes que d'autres (*skewed datasets*).\n",
    "\n",
    "### Matrice de confusion (*confusion matrix*)\n",
    "\n",
    "Une bien meilleure manière d'évaluer la performance d'un classificateur est de regarder sa *matrice de confusion*. L'idée générale est de compter le nombre de fois que les instances d'une classe A sont classifiée comme classe B. Par exemple, pour connaître le nombre de fois qu'un classificateur a confondu les images de 5 avec des images de 3, on pourrait regarder dans la cinquième ligne, troisième colonne de la matrice de confusion.\n",
    "\n",
    "Pour calculer la matrice de confusion, on a d'abord besoin d'un *jeu de prédictions qui peuvent être comparées au cibles (*targets*) réelles. On pourrait faire des prédictions sur le JdT, mais il vaut mieux le laisser intouché (rappel : on ne l'utilise qu'à la toute fin du projet, une fois qu'on a un classificateur prêt à être déployé).\n",
    "\n",
    "À la place, on peut utiliser la fonction `cross_val_predict` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la fonction cross_val_score, la fonction cross_val_predict va faire une validation croisée à k-blocs, mais au lieu de retourner le score d'évaluation, il va retourner les prédictions faites sur chaque bloc de test. Cela signifie qu'on va avoir une prédiction propre pour chaque instance dans le JdE (\"propre\" signifie que la prédiction est faire par un modèle qui n'a jamais vu les données durant l'entraînement).\n",
    "\n",
    "On peut maintenant avoir la matrice de confusion, en utilisant la fonction `confusion_matrix()`. Il y a simplement besoin de lui passer les classes des cibles (*y_train_5*), et les classes des prédictions (*y_train_pred*) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque ligne dans une matric de confusion représente *une vraie classe*, tandis que chaque colonne représente une *classe prédite*. La première ligne de cette matrice prend en considération les images \"non 5\" (la classe *négative*) : 53892 d'entre elles ont été correctement classifées en tant que \"non 5\" (**vrai négatifs**), tandis que les 687 restant ont été faussement claissifée en tant que 5 (**faux positif**). La seconde ligne prend en considération les images \"5\" : 1891  ont été faussement classifiées en tant que \"non 5\" (**faux négatif**), alors que 3530 ont été correctement classifées en tant que \"5\" (**vrai positif**). Un classificateur parfait n'aurait que des vrais positifs et des vrais négatifs, et donc la matrice de confusion n'aurait que des 0 dans sa diagonale principale (bas gauche, haut droit) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54579,     0],\n",
       "       [    0,  5421]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_prefect_predictions = y_train_5 # on prétend avoir atteint la perfection\n",
    "confusion_matrix(y_train_5, y_train_prefect_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion donne beaucoup d'informations, mais il est parfois préférable d'avoir des mesures précises. Une mesure intéressante à regarder est la précision des prédictions positives, appeléé `précision` par le classificateur :\n",
    "\n",
    "$precision = TP/(TP+FP)$\n",
    "\n",
    "- TP = nombre de Vrai Positifs\n",
    "- FP = nombre de Faux Positifs\n",
    "\n",
    "Un moyen très facile d'obtenir une précision de 100% est de faire une unique prédiction et de s'assurer qu'elle est correcte ($precision = 1/1 = 100%$). Mais cema ne serait pas très utile, puisque le classifictateur ingorerait tout sauf une unique instance positive. Donc la précision est liée à une autre mesure appelée le `rappel` (`recall`) ou `sensibilité` (ou encore *True positive rate*, TRP) : c'est le ratio d'instances positives qui sont correctement détectées par le classificateur :\n",
    "\n",
    "$ recal = TP / (TP + FN)$\n",
    "\n",
    "- FN : Faux Négatif\n",
    "\n",
    "### Précision et rappel (*precision and recall*)\n",
    "\n",
    "Scikit-Learn fournit plusieurs fonctions pour calculer les mesures des classificateurs, dont la précision et le rappel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre détecteur de 5 n'est plus aussi glorieux que lors de notre première évaluation."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
