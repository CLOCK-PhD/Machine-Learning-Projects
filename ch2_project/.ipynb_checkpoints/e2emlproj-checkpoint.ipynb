{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Machine Learning Project\n",
    "\n",
    "Projet du chapitre 2 du livre de Aurélien Géron, où l'on va passer par les étapes normales pour s'occuper d'un projet de ML :\n",
    "\n",
    "- Regarder le projet dans son ensemble;\n",
    "- Obtenir les données;\n",
    "- Découvrir et visualiser les données pour avoir un aperçu;\n",
    "- Préparer les données pour l'algo de ML;\n",
    "- Sélectionner un modèle et l'entraîner;\n",
    "- Affiner le réglage du modèle;\n",
    "- Présenter sa solution;\n",
    "- Lancer, gérer et maintenir le système.\n",
    "\n",
    "Dans ce projet, on va agir comme un data scientist récemment employé par une entreprise de gestion immobilière.\n",
    "\n",
    "## Travailler avec de vraies données\n",
    "\n",
    "Il est souvent plus intéressant de travailler avec de vraies données existantes plutôt que des jeux de données artificiels.\n",
    "Ici, on utilisera le jeu de données \"California Housing Prices\" du StatLab Repository, basé sur les données du California Census de 1990.\n",
    "\n",
    "## Regarder le projet dans son ensemble\n",
    "\n",
    "La première étape est d'utiliser le California Census pour construire un modèle des prix des maisons dans l'état. Ces données incluent des mesures comme la population, le revenu médian, et le prix médian du loyer pour chaque \"bloc\", qu'on appelera districts (regroupement de 600 à 3000 habitants).\n",
    "\n",
    "Le modèle devrait apprendre à partir de ces données et devrait être capable de prédire le prix du loyer médian dans chaque district, étant donné les autres mesures.\n",
    "\n",
    "## Cerner le problème\n",
    "\n",
    "Il est important de se demander quel est l'objectif derrière la construction de ce modèle. Connaître l'objectif est important car il va permettre de déterminer comment on va cerner le problème, quel algorithme on va choisir, quelle mesure de performance on va utiliser pour évaluer le modèle, et quelle quantité d'effort on va fournir pour le \"tordre\".\n",
    "\n",
    "Dans ce projet, la sortie de notre modèle sera donné à un autre système de ML. Ce système va déterminer s'il est intéressant d'investir dans une zone donnée ou non. Il est important que cela soit fait de manière correcte, car cela affectera directement les revenus.\n",
    "\n",
    "Il est aussi important de savoir comment la solution est gérée avant l'implémentation du modèle de ML.\n",
    "Dans notre cas, c'est fait à la main, et quand les données sont insuffisantes, les employés dédiés à la tâche ont des estimations pas top. S'ils parviennent à estimer le prix médian, il y a souvent un écart de plus de 20% avec la réalité. D'où l'idée d'entraîner un modèle pour prédire le loyer médian d'un distric, étant donné qu'on a des données pour les autres districts. Les données du census ont l'air d'être un très bon jeu de données à exploiter dans ce but, puisqu'il inclut les prix médians des loyers des centaines de districts, ainsi que d'autres données.\n",
    "\n",
    "Avec ces informations, on peut commencer à concevoir le système. Premièrement, on va devoir cerner le problème : supervisé ou non ? ou apprentissage par renforcement ?\n",
    "\n",
    "On a ici clairement affaire à un _problème supervisé_, puisqu'on va utiliser des jeux d'entraînement _labelisés_.\n",
    "\n",
    "Il s'agit également d'une tâche de _régression_, puisqu'on doit _prédire une valeur_. Plus spécifiquement, d'une _régression multiple_, puisque le système va utiliser plusieurs caractéristiques pour faire une prédiction (revenu médian, population du district, etc.).\n",
    "\n",
    "C'est également une régression _univariée_ puisqu'on essayer de prédire seulement une valeur pour chaque district. Si on essayait de prédire de multiples valeurs par discrit, il s'agirait d'un problème _multivarié_.\n",
    "\n",
    "Enfin, puisqu'il n'y a pas de flot de données continu arrivant au système, il n'est pas nécessaire de s'ajuster à un changement rapide des données, et le jeu de donnée est assez petit pour passer en mémoire, donc le _batch learning_ devrait aller très bien pour ce cas (si les données étaient énormes, on aurait pu faire du batch learning sur plusieurs serveurs, ou utiliser du _online learning_).\n",
    "\n",
    "## Sélectionner une mesure de performance\n",
    "\n",
    "L'étape suivante est la sélection d'une mesure de performance. Une mesure de performance typique pour les problèmes de régression est la RMSE (Root Mean Square Error). Elle donne une idée de combien d'erreurs le système fait typiquement dans ses prédictions, avec un poids plus important pour les grosses erreurs.\n",
    "\n",
    "Equation de la RMSE (Racine de l'erreur quadratique moyenne) :\n",
    "\n",
    "$sqrt{\\sum_{i=1}^{10} t_i}$ (à compléter)\n",
    "\n",
    "Même si le RMSE est est généralement la mesure de preformance privilégiée pour les tâches de régression, il est possible dans certains contextes d'utiliser d'autres équations. Par exemple, supposons qu'il y ait des districts _outliers_ ; dans ce cas, on pourrait considérer l'utilisation de la _mean absolute error_ (MAE, aussi appelée _average absolute error_).\n",
    "\n",
    "Equation de l'Erreur absolue moyenne : (à remplir)\n",
    "\n",
    "La RMSE et la MAE sont des moyens de mesurer la distance entre deux vecteurs : le vecteur de prédiction et le vecteur de valeur cible. De nombreuses mesures de distances, ou _normes_, sont possibles :\n",
    "- Calculer la RMSE correspond à la _norme euclidienne_; également appelé $l_{2}$ _norm_\n",
    "- Calculer la MAE à la $l_{1}$ _norm_. Parfois appelée norme de Manhatthan, parce qu'elle mesure la distance entre deux points dans une ville ou on ne peut que se déplacer le long de blocs.\n",
    "- Plus généralement, la $l_{k}$_norm_ d'un vecteur __v__  contenant _n_ éléments est défini comme ||v||_{k} = (|v_{0}|^k) ... (à compléter)\n",
    "- Plus l'index de la norme est élevé, plus il va se focaliser sur les grande valeurs et négliger les petites valeurs. C'est pourquoi le RMSE est plus sensible aux _outliers_ que la MAE. Mais quand les _outliers_ sont exponentiellement rare, le RMSE a une très bonne performance et est généralement préféré.\n",
    "\n",
    "## Vérifier les suppositions\n",
    "\n",
    "Enfin, il est important de lister et de vérifier les suppositions qui ont été faites ;  cela permet de repérer des problèmes dès le début.\n",
    "\n",
    "Par exemple, dans notre cas, les prix des districts que notre système va fournir en sortie seront donnés à un autre système de ML et on assume que les prix vont être utilisés en tant que tels. Mais que se passerait-il si le système en aval converti les prix en catégories (comme \"bon marché\", \"cher\") et utilise ensuite les catégories plutôt que les prix ? Dans ce type de situation, donner parfaitement le juste prix n'est pas important du tout, le système n'ayant besoin que d'une bonne catégorie. Dans ce cas, le problème ne devrait pas être traîté comme une tâche de régression mais une tâche de classification. C'est le genre de chose qu'on ne souhaite pas découvrir après avoir mis en place le modèle.\n",
    "\n",
    "Heureusement, dans notre cas, il s'agit bien d'une régression et on va pouvoir passer à la partie code !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
